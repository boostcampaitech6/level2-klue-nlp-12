# ğŸ†**Level2 KLUE Project - Relation Extraction**



## ğŸ–¥ï¸ Project Introduction
|**ê°œìš”**|**Description**|
|:--:|--|
|**ì£¼ì œ** | **`Relation Extraction`** : ë¬¸ì¥ ë‚´ ë‘ ê°œì²´ëª… ìŒ (entity pair) ê°„ ê´€ê³„ ì¶”ì¶œ |
|**ëª©í‘œ**| ëª¨ë¸ í•™ìŠµì„ í†µí•´ `sentence`ì™€ ë¬¸ì¥ ë‚´ ë‘ ê°œì²´ `subject entity`, `object entity` ê°„ì˜ ê´€ê³„ ë¶„ë¥˜ |
|**í‰ê°€ ì§€í‘œ**| micro f1 score |
|**ë°ì´í„°**|Train (32470ê°œ), Test (7765ê°œ) from Wikitree, Wikipedia, Policy_briefing |
|**í˜‘ì—… í™˜ê²½**|**`Notion`**(ì‹¤í—˜ ìƒí™© ê³µìœ ), **`Github`**(ì½”ë“œ ë²„ì „ê´€ë¦¬), **`Slack`**(ì‹¤ì‹œê°„ ì†Œí†µ) |


<br>

## ğŸ–ï¸**Leader Board**
### **ğŸ¥ˆPrivate Leader Board(1ìœ„)**
![Alt text](./resource/1.png)

### **ğŸ¥‰Public Leader Board(3ìœ„)**
![Alt text](./resource/2.png)



<br>

## ğŸ‘¼**Member's role**
|**Member**|**Role**|
|--|--|
|[**ì†ìœ¤í™˜**](https://github.com/Yunan31)| ì „ì²˜ë¦¬ í•¨ìˆ˜ ë³€ê²½, Tokenizing ì‹¤í—˜ (Type entity marker, special token ë“±), ì•™ìƒë¸” baseline êµ¬í˜„ (hard voting)|
|[**ìµœìƒˆì—°**](https://github.com/new-open)|ë°ì´í„° ì¦ê°• (ë™ì˜ì–´ ì¹˜í™˜/ì‚½ì…), semantic typing ë°ì´í„°ì…‹ êµ¬ì¶•, github í˜‘ì—… ê´€ë ¨ template ì œì‘ (PR, issue)|
|[**í—ˆì¬í•˜**](https://github.com/jaehahuh)|Baseline model codeì— ê¸°ëŠ¥ ì¶”ê°€ ë° êµ¬í˜„, optimizer and scheduler(AdamP, SGD ë“±) êµ¬í˜„ ë° ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸|
|[**í™©ê¸°ì¤‘**](https://github.com/merri4)|EDA (labelë³„ ì˜¤ë‹µë¥  ë¶„ì„, unk í† í° ì˜í–¥ ë¶„ì„), ë°ì´í„° ì¦ê°• (ë¶€ì‚¬ ì¹˜í™˜), ëª¨ë¸ ì‹¤í—˜ (koelectra, funnel, bert), TAPT (roberta-large), ì•™ìƒë¸” baseline êµ¬í˜„ (softmax weighted sum)|
|[**í™©ì¸ìˆ˜**](https://github.com/In-Soo-Hwang)|EDA (entity pair - label ë¶„í‘œ ë° ë¹„ìœ¨ í™•ì¸), ì•™ìƒë¸” baseline êµ¬í˜„ (mean, weighted sum)|

<br>


## ğŸ“…**Project Process**

* í”„ë¡œì íŠ¸ëŠ” 2024-01-03 ~ 2024-01-18 15ì¼ê°„ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.

![Alt text](./resource/3.png)

<br>

## ğŸ•µï¸**What we did**

![Alt text](./resource/4.png)

|**Process**|**What we did**|
|:--:|--|
|**Dev Dataset êµ¬ì¶•**| ì•Œë ¤ì§„ Test datasetì˜ label ë¶„í¬ì™€ ìœ ì‚¬í•˜ê²Œ train data split |
|**EDA**| ë ˆì´ë¸”ë³„ ë¶„í¬ ë¶„ì„, Baseline ëª¨ë¸ ì˜ˆì¸¡ê³¼ ì‹¤ì œê°’ ì°¨ì´ ì •ì„± ë¶„ì„ |
|**Preprocessing**| subject/object entity ì‰¼í‘œ ì²˜ë¦¬ |
|**Augmentation**|ë™ì˜ì–´ ì¹˜í™˜ (Synonym Replacement), ë™ì˜ì–´ ì‚½ì… (Synonym Insertion), ë¶€ì‚¬ ì¹˜í™˜ (Adverb Replacement), Entity pair swap |
|**Entity Marker**| Entity marker, special token ì‚¬ìš©, Typed Entity marker, Type entity marker (punct) |
|**Semantic Typing**| sentence + ê´€ê³„ ì§ˆë¬¸ ì¶”ê°€ |
|**Experiment Model**| roberta-base, roberta-large, koelectra-v3-discriminator, electra-kor-base, funnel-kor-base, bert-base |
|**TAPT**| roberta-large + MLM |
|**Ensemble**| soft voting (mean, weighted sum), hard voting |


<br>



## **ğŸ“Directory Structure**

### **ğŸ“ë””ë ‰í† ë¦¬**
* í•™ìŠµ ë°ì´í„° ê²½ë¡œ : `./data`
* í•™ìŠµ ì½”ë“œ ê²½ë¡œ : `./code`


### **ğŸ“ğŸ“ì½”ë“œ**
1. **ë°ì´í„° ì¦ê°•** : `./code/augmentation.py`
1. **TAPT** : `./code/prepretraining.py`
1. **í•™ìŠµ** : `./code/train.py`, `./code/pl_train.py`
2. **ì¶”ë¡ ** : `./code/inference.py`, `./code/pl_inference.py`
4. **ì•™ìƒë¸”** : `./code/ensemble.py`

```
ğŸ“level2-klue-nlp-12
â”œâ”€code
â”‚  augmentation.py
â”‚  custom_train.py
â”‚  ensemble.py
â”‚  inference.py
â”‚  load_data.py
â”‚  pl_inference.py
â”‚  pl_train.py
â”‚  prepretraining.py
â”‚  requirements.txt
â”‚  train.py
â”‚          
â””â”€data
   â”œâ”€train
   â”‚  train.csv
   â”‚  
   â”œâ”€dev
   â”‚  dev.csv
   â”‚  
   â”œâ”€test
   â”‚  test_data.csv

```
<br>

## **ğŸ’»How to Start**

### **í™˜ê²½ ì„¸íŒ…**
```
> pip install -r requirements.txt
```


### **ğŸ“ŠPretrain (optional)**
```
> python ./code/prepretraining.py
```

### **ğŸ¤–Train**
```
> python ./code/train.py
```
ë˜ëŠ” 
```
> python ./code/pl_train.py
```

### **ğŸ¤–Infer**

```
> python ./code/inference.py
```
ë˜ëŠ” 
```
> python ./code/pl_inference.py
```


### **ğŸ¤–Ensemble**
```
> python ./code/ensemble.py --technique mean
```

<br>


## ğŸ“„ Reference

James Y. Huang et al. (2022). "Unified Semantic Typing with Meaningful Label Inference". [arXiv:2205.01826](https://arxiv.org/abs/2205.01826)


Byeongho Heo et al. (2021). "AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights". [arXiv:2006.08217](https://arxiv.org/abs/2006.08217)


Wenxuan Zhou and Muhao Chen (2022). "An Improved Baseline for Sentence-level Relation Extraction". [arXiv:2102.01373](https://arxiv.org/abs/2102.01373)


Suchin Gururangan et al. (2020). "Don't Stop Pretraining: Adapt Language Models to Domains and Tasks". [arXiv:2102.01373](https://arxiv.org/abs/2102.01373)

